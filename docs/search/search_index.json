{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Project Requirements","text":""},{"location":"#executive-summary","title":"Executive summary","text":"<p>The Aquatic Biosphere Project of Canada engages individuals of all ages and backgrounds with Canada\u2019s aquatic biosphere through presentations and media, community programs, and an upcoming public attraction. To that end, they hope to develop an Android/iOS application that uses augmented reality (AR) to enhance the device\u2019s camera with fun and informative content about Canada\u2019s nature. At the moment, the application is not funded. Our product will show potential investors that such an application is possible, hopefully securing funding for the Aquatic Biosphere Project to further develop the application.</p> <p>When a user first opens the product, they will confirm their location in order to ensure the accuracy of the displayed information. The product will then open the device camera, and the user will be free to use it to scan their environment. When the user brings a relevant object into the camera view, the product will augment the object with the appropriate AR objects. Note that the product will only be tailored to environments within the University of Alberta North Campus.</p>"},{"location":"#project-glossary","title":"Project Glossary","text":"<ul> <li>augment - add additional virtual objects into the camera view so that the objects look as if they are there in 3d space</li> <li>camera view - the live camera feed of a device that is made visible on the device\u2019s screen</li> <li>device - a handheld computing device with an integrated camera and a screen, running the android/ios operating system</li> <li>application - software running on a device; in the context of the summary, it refers mostly to the proposed but undeveloped future application</li> <li>product - the proof-of-concept application currently being developed</li> <li>AR object - augmented-reality object; fun or educational information, which may come in the form of 3d models, lines of text, images, among other mediums</li> <li>environment - a set location with visible objects that remain fairly consistent; this will be used to consistently test different camera views</li> <li>surface - flat plane in the real world on which the AR objects are augmented on. It can be determined either by recognition or by the user; e.g. pond, marsh, park</li> </ul>"},{"location":"#user-stories","title":"User Stories","text":"Index User Story Story Point Acceptance test MoSCoW US 01.01 As a User, I want the system to identify my location, so that I can share it with the app. 3 <li> User's location is identified. </li> Must US 01.02 As a user, I want to be able to enter my location manually or change it, if it is incorrect. 3 <li> User's location information is changed to the new manually selected one. </li> Must US 01.03 As a user, I want to be able to select a surface that I\u2019m pointing at from a drop down menu, to optimize the AR experience 2 <li> User's selected surface is correctly marked as the AR objects's spawn location. </li> Must US 01.04 As a User, I want the app to access my camera, so that it can display Augmented objects. 2 <li> User's Camera is opened.</li> Must US 01.05 As an admin, I want to be able to add more 3D models, to increase user engagement. 2 <li> New models and their info are added to the DB. </li> Must US 02.01 As a user, I want to be able to view augmented objects on my screen, so that I can interact with them. 5 <li> User can see appropriately placed AR objects. Must US 02.02 As a user, I want to be able to view a brief description about the ecosystem I\u2019m looking at, so that I know what to expect. 3 <li> User can see information about the ecosystem in a new activity. </li> Should US 02.03.01 As a user, I want to be able to click on an augmented object, so that I can learn information about it. 3 <li> User is viewing an augmented object through their camera. </li> Must US 02.03.02 As a user, I want to be able to navigate to external links for each object, so that I can gather more information. 3 <li>From the popup information screen, user can click on a link to go to an external site where they learn more about the object. </li> Should US 02.03.03 As a user, I want to be able to exit out of external information tabs, so that I can view other Augmented objects. 3 <li>From the external information screen, user can click on exit/back button and be back to the camera screen. </li> Should US 03.01 As a user, I want to create an account, so I can save my progress and interaction information on the app 5 <li>User can select \"Forgot Password\" on the login screen.</li> <li> User can enter their email and receive a reset link. </li> <li> User can log in with their new password.</li> Could US 03.02 As a user, I want to login to my account, to get a personalized experience. 5 <li>User opens the app and can see a login screen.</li> <li> User can enter their credentials and log in to their account.</li> <li> User can choose \"Forgot Password\" to recover their account.</li> Could US 03.03 As a user, I want to be able to save object information in my records, so that I can read about it later. 5 <li>User can select an object.</li> <li> User can choose to save selected object.</li> <li> User can see a list of saved objects.</li> Could US 04.01 As a user, I want to be able to identify a species (eg. A real life plant) through the app, so that I can recognize new species. 8 <li> User can point camera at a species.</li> <li> User can see information on possible matches for that species. </li> Would like, but won't get US 04.02 As a user, I want to be able to share my findings with others, so that I can help others find those objects/species. 8 <li> User can press share and select other users.</li> <li> Other users can receive and see the object and its information. </li> Would like but won't get"},{"location":"#similar-products","title":"Similar Products","text":"<ul> <li>ARCore Elements: </li> <li>Demo app by Google using ARCore platform. </li> <li>Has tips for User Movement, User Interface and Object Movement.</li> </ul>"},{"location":"#open-source-products","title":"Open Source Products","text":"<ul> <li>https://github.com/viromedia/figment-ar: AR app built with ViroReact</li> <li>https://github.com/Unity-Technologies/arfoundation-samples/: AR app demo built with Unity's AR Foundation</li> </ul>"},{"location":"#technical-resources","title":"Technical Resources","text":"<ul> <li>AR Engine: Unity</li> <li>Unity as a library in other applications</li> <li>Platform: AR Foundation     Created by Unity, has support for ARCore by Google and ARKit by Apple.</li> <li>Unity Mars: Integrates with AR Foundation to build apps </li> <li>Google's guide on getting started with AR Foundation</li> <li>Create an AR game using Unity's AR Foundation</li> <li>ViroReact: Integrate directly with React Native. No longer in development</li> <li>Other resources: TBD</li> </ul>"},{"location":"pages/management/","title":"Project Management","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Fames ac turpis egestas sed tempus. Aliquam ultrices sagittis orci a scelerisque purus semper. Lectus proin nibh nisl condimentum. Pharetra massa massa ultricies mi quis hendrerit. Ornare arcu odio ut sem. Proin nibh nisl condimentum id. Venenatis lectus magna fringilla urna porttitor rhoncus dolor. Ac tortor vitae purus faucibus. Quam quisque id diam vel quam. Massa tempor nec feugiat nisl pretium. Velit sed ullamcorper morbi tincidunt ornare massa eget. Nisl nisi scelerisque eu ultrices vitae auctor eu augue ut. Eu lobortis elementum nibh tellus molestie nunc. Lacus vestibulum sed arcu non. Faucibus et molestie ac feugiat sed lectus vestibulum mattis.</p> <p>Nulla porttitor massa id neque aliquam vestibulum morbi blandit. Nisl suscipit adipiscing bibendum est ultricies integer quis auctor. A cras semper auctor neque vitae tempus. Tristique risus nec feugiat in fermentum. Urna cursus eget nunc scelerisque viverra mauris. Vestibulum sed arcu non odio euismod. Vitae sapien pellentesque habitant morbi. Consectetur adipiscing elit pellentesque habitant morbi tristique senectus et netus. Consequat semper viverra nam libero justo laoreet. Non enim praesent elementum facilisis leo vel fringilla est. Ullamcorper sit amet risus nullam eget felis eget nunc.</p>"},{"location":"pages/management/#story-map","title":"Story map","text":""},{"location":"pages/software/","title":"Software Design","text":""},{"location":"pages/software/#architecture-diagram","title":"Architecture Diagram","text":"<p>Our project will use the N-tier layered architecture format, we plan on using React Native and Unity3D for the user interface of the presentation layer, and the main logic of our app will be contained in Unity3D. Google Maps API will be used in the business layer to assist location detection. We will use Unity3D to build all AR related functionality through the AR Foundation Framework that allows adaptation to both Android and iOS without further changes. Tentatively, we want to use Django ORM as the persistence layer for accessing AR model data, and a PostgreSQL database for storing 3D models that we will use for the AR experience. Currently we plan on hosting the backend database on a Google Cloud server. This architecture diagram may be subjected to change in future sprints. </p> <p></p>"},{"location":"pages/software/#uml-class-diagram","title":"UML Class Diagram","text":"<p>Our app can be divided into a number of central classes along with some helper ones. The user class makes calls that get the app user up and running like making calls that obtain the user's current location using the Location class (which further makes use of the class GeocoderResult that Google Maps API uses). The Camera class is responsible for displaying AR objects (which are classed as ARObject). ARObjects are heavily reliant on x, y, and z coordinates, which is why having a 3D vector class, Vector3, is convenient.</p> <p></p>"},{"location":"pages/software/#sequence-diagram","title":"Sequence Diagram","text":"<p>The sequence diagram features the four most important interactions in our app: login, location recognition, camera view, and information view. From opening the app, users may choose to login. After which, all users must set their location either automatically through a built in maps API, or manually enter their location if the GPS is incorrect. Once location is set, users will be navigated to their camera view that allows them to point their camera at aquatic objects in order to see an AR of said object on screen. Users may view information about objects by clicking on them, where they may choose to navigate further to external Wiki sites through embedded links. Users may choose to save objects to their account database, if logged in. </p> <p></p>"},{"location":"pages/software/#low-fidelity-user-interface","title":"Low-Fidelity User Interface","text":"<p>Wireframes are used to show the overall look and feel of your app, as well as the high-level user-interaction design. Looking at the wireframes, anyone should be able to get an idea of what will be developed. Low fidelity wireframes are just a quick sketch that can make ideas more tangible. They are focused on the \u201cbig picture\u201d of the project.</p> <p>Wireframes for this project were made using Balsamiq. They provide a clear overview of the app structure, layout, information architecture, user flow, functionality, and intended behaviors.</p> <p></p>"},{"location":"pages/teamwork/","title":"Team Work","text":""},{"location":"pages/teamwork/#team-canvas","title":"Team Canvas","text":"<p>Below is the team canvas for our team </p>"},{"location":"pages/teamwork/#belbin-roles","title":"Belbin Roles","text":"<p>See https://www.belbin.com/about/belbin-team-roles.</p> Name Preferred Roles Manageable Roles Least Preferred Roles Mohammad Hammad IMP, CF, SP PL, TW, ME SH, RI, CO Raunak Agarwal SH, RI, IMP CO, PL, SP ME, TW, CF Vaibhav Chugh CO, IMP, CF ME, RI, SP SH, PL, TW Yui Han ME, IMP, CF SP, PL, SH RI, TW, CO Huy Ta CF, CO, TW SP, IMP, ME PL, SH, RI Kevin Sha PL, ME, IMP SH, SP, CF RI, CO, TW"},{"location":"pages/teamwork/#thinking-roles","title":"Thinking Roles","text":""},{"location":"pages/teamwork/#pl-plant","title":"PL (Plant)","text":"<p>Tends to be highly creative and good at solving problems in unconventional ways.</p> Preferred Manageable Kevin Sha Mohammad Hammad Raunak Agarwal Yui Han"},{"location":"pages/teamwork/#me-monitor-evaluator","title":"ME (Monitor Evaluator)","text":"<p>Provides a logical eye, making impartial judgements where required and weighs up the team's options in a dispassionate way.</p> Preferred Manageable Yui Han Mohammad Hammad Kevin Sha Vaibhav Chugh Huy Ta"},{"location":"pages/teamwork/#sp-specialist","title":"SP (Specialist)","text":"<p>Brings in-depth knowledge of a key area to the team.</p> Preferred Manageable Mohammad Hammad Raunak Agarwal Vaibhav Chugh Yui Han Huy Ta Kevin Sha"},{"location":"pages/teamwork/#action-roles","title":"Action Roles","text":""},{"location":"pages/teamwork/#sh-shaper","title":"SH (Shaper)","text":"<p>Provides the necessary drive to ensure that the team keeps moving and does not lose focus or momentum.</p> Preferred Manageable Raunak Agarwal Yui Han Kevin Sha"},{"location":"pages/teamwork/#imp-implementer","title":"IMP (Implementer)","text":"<p>Needed to plan a workable strategy and carry it out as efficiently as possible.</p> Preferred Manageable Mohammad Hammad Huy Ta Vaibhav Chugh Raunak Agarwal Yui Han Kevin Sha"},{"location":"pages/teamwork/#cf-completer-finisher","title":"CF (Completer Finisher)","text":"<p>Most effectively used at the end of tasks to polish and scrutinise the work for errors, subjecting it to the highest standards of quality control.</p> Preferred Manageable Mohammad Hammad Kevin Sha Vaibhav Chugh Yui Han Huy Ta"},{"location":"pages/teamwork/#people-roles","title":"People Roles","text":""},{"location":"pages/teamwork/#ri-resource-investigator","title":"RI (Resource Investigator)","text":"<p>Uses their inquisitive nature to find ideas to bring back to the team. </p> Preferred Manageable Raunak Agarwal Vaibhav Chugh"},{"location":"pages/teamwork/#tw-teamworker","title":"TW (Teamworker)","text":"<p>Helps the team to gel, using their versatility to identify the work required and complete it on behalf of the team.</p> Preferred Manageable Huy Ta Mohammad Hammad"},{"location":"pages/teamwork/#co-co-ordinator","title":"CO (Co-ordinator)","text":"<p>Needed to focus on the team's objectives, draw out team members and delegate work appropriately.</p> Preferred Manageable Vaibhav Chugh Raunak Agarwal Huy Ta"}]}